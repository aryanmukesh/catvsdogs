library(keras)
library(reticulate)
install_keras()
base_dir <- "~/CNN/"
train_dir <- file.path(base_dir, "train")
validation_dir <- file.path(base_dir, "validation")
test_dir <- file.path(base_dir, "test")

# using image_data_generator to read images from the directories
# this function converts images to preprocessed tensors

train_datagen <- image_data_generator(rescale = 1/255)
validation_datagen <- image_data_generator(rescale = 1/255)

# Infinite loop for flowing images in batches of 20

train_generator <- flow_images_from_directory(
	train_dir, 
	train_datagen,
	target_size = c(150,150),
	batch_size = 20,
	class_mode = "binary"
)

validation_generator <- flow_images_from_directory(
	validation_dir,
	validation_datagen,
	target_size = c(150,150),
	batch_size = 20,
	class_mode = "binary"
)

# Model Architecture 

model <- keras_model_sequential() %>%
	layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu",
			input_shape = c(150, 150, 3)) %>%
	
	layer_max_pooling_2d(pool_size = c(2,2)) %>%
	
	layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
	
	layer_max_pooling_2d(pool_size = c(2,2)) %>%
	
	layer_conv_2d(filters = 128, kernel_size = c(3,3), activation = "relu") %>%
	
	layer_max_pooling_2d(pool_size = c(2,2)) %>%
	
	layer_conv_2d(filters = 128, kernel_size = c(3,3), activation = "relu") %>%
	
	layer_max_pooling_2d(pool_size = c(2,2)) %>%
	
	layer_flatten() %>%
	layer_dense(units = 512, activation = "relu") %>%
	layer_dense(units = 1, activation = "sigmoid")

model 

# compiling the model

model %>% compile(
	loss = "binary_crossentropy",
	optimizer = optimizer_rmsprop(lr = 1e-4), 
	metrics = c("acc"))


# Fitting the model with fit_generator function 
# Steps_per_epoch controls the infinite loop 

history <- model %>% fit_generator(
	train_generator, steps_per_epoch = 100, epochs=20,
	validation_data = validation_generator, validation_steps = 50 )

#Saving the model

model %>% save_model_hdf5("cats_and_dogs_small_1.h5")

# Displaying curves of loss and accuracy during training 

plot(history) 




# "DATA AUGMENTATION PART" --------------------------



# Using image_data_generator to create new image data

datagen <- image_data_generator(
	rescale = 1/255,
	rotation_range = 40,
	width_shift_range = 0.2,
	height_shift_range = 0.2,
	shear_range = 0.2,
	zoom_range = 0.2, 
	horizontal_flip = TRUE,
	fill_mode = "nearest")

test_datagen <- image_data_generator(rescale = 1/255)

train_generator <- flow_images_from_directory(
	train_dir,
	datagen,
	target_size = c(150,150),
	batch_size = 32,
	class_mode = "binary")

validation_generator <- flow_images_from_directory(
	validation_dir,
	test_datagen,
	target_size = c(150,150),
	batch_size = 32,
	class_mode = "binary" )

# Model Architecture for augmented data

model <- keras_model_sequential() %>%
	layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = "relu",
			input_shape = c(150, 150, 3)) %>%
	
	layer_max_pooling_2d(pool_size = c(2,2)) %>%
	
	layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = "relu") %>%
	
	layer_max_pooling_2d(pool_size = c(2,2)) %>%
	
	layer_conv_2d(filters = 128, kernel_size = c(3,3), activation = "relu") %>%
	
	layer_max_pooling_2d(pool_size = c(2,2)) %>%
	
	layer_conv_2d(filters = 128, kernel_size = c(3,3), activation = "relu") %>%
	
	layer_max_pooling_2d(pool_size = c(2,2)) %>%
	
	layer_flatten() %>%
	layer_dense(units = 512, activation = "relu") %>%
	layer_dense(units = 1, activation = "sigmoid")

# compiling the model

model %>% compile(
	loss = "binary_crossentropy",
	optimizer = optimizer_rmsprop(lr = 1e-4), 
	metrics = c("acc"))


# Fitting the model with fit_generator function 
# Steps_per_epoch controls the infinite loop 

history2 <- model %>% fit_generator(
	train_generator, steps_per_epoch = 100, epochs=20,
	validation_data = validation_generator, validation_steps = 50 )
